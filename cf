#!/usr/bin/perl
use warnings;
use strict;
use Getopt::Long;
use POSIX qw(strftime);
use FindBin qw($Bin);
use lib "$FindBin::Bin/";
# use File::HomeDir;
use Clusterflow;
use Data::Dumper;

my $version = '0.0.1';

# my $homedir = File::HomeDir->my_home;
my $homedir = $ENV{"HOME"};

# Read global config variables in. Do in order so that local prefs overwrite.
my %config;
my @config_files = ("$FindBin::Bin/clusterflow.config", "$homedir/clusterflow.config", './clusterflow.config');
foreach my $config_file (@config_files){
	if(-e $config_file){
		open (CONFIG, $config_file) or die "Can't read $config_file: $!";
		my $comment_block = 0;
		while (<CONFIG>) {
			chomp;
			s/\n//;
			s/\r//;
			if($_ =~ /^\/\*/){
				$comment_block = 1;
				next;
			}
			if($_ =~ /^\*\//){
				$comment_block = 0;
				next;
			}
			if($_ =~ /^\@/ && !$comment_block){
				my @sections = split(/:/, $_, 2);
				$config{substr($sections[0], 1)} = $sections[1];
			}
		}
		close(CONFIG);
	}
}

# Get command line parameters
my $split_files = 1;
my $file_list;
my $cl_email;
my $cl_priority;
my $cl_total_cores;
my $cl_total_mem;
my $cl_notifications;
my $cl_dryrun;
my $cl_version;
my $cl_help;

my $config_result = GetOptions(
	"split_files=i" => \$split_files,
	"file_list=s" => \$file_list,
	"email=s" => \$cl_email,
	"priority=s" => \$cl_priority,
	"cores=i" => \$cl_total_cores,
	"mem=s" => \$cl_total_mem,
	"notifications=s"  => \$cl_notifications,
	"dryrun" => \$cl_dryrun,
	"version" => \$cl_version,
	"help" => \$cl_help
);

die "Could not parse options" unless ($config_result);

# Get the file list
my $pipeline = shift(@ARGV);
my @files = @ARGV;

if($cl_dryrun){
	print "Cluster Flow is running in Dry Run mode. No cluster jobs will be set off, only printed. Run files will be created.\n\n";
}
if($cl_version){
	print "Cluster Flow v$version\n\n";
	exit;
}
if($cl_help){
	print "Cluster Flow v$version\nSyntax: cf [flags] pipeline_name file_1 file_2..\n\n";
	exit;
}
if(!$pipeline){
	die("Error - no pipeline specified. Use --help for instructions.\nSyntax: cf [flags] pipeline_name file_1 file_2..\n")
}

# Set up parameters
if($cl_email){
	$config{email} = $cl_email;
}
if($cl_priority){
	$config{priority} = $cl_priority;
}
if($cl_total_cores){
	$config{total_cores} = $cl_total_cores;
}
if($cl_total_mem){
	$config{total_mem} = $cl_total_mem;
}

if($cl_notifications){
	$config{notifications} = $cl_notifications;
}
my @notifications = split(",", $config{notifications});

# Load in the pipeline config file
my @pipeline_folders = ('./', "$homedir/clusterflow/pipelines/", "$Bin/pipelines/");
foreach (@pipeline_folders){
	if(-e $_."$pipeline.config"){
		open (CONFIG,$_."$pipeline.config") or die "Can't read ".$_."$pipeline.config: $!";
		last;
	}
}
if(tell(CONFIG) == -1){
	die "Can't find pipeline config file $pipeline.config";
}

my $runfile;
my %module_tree;
my @indents;
push @indents, \%module_tree;
my $comment_block = 0;

# Write all config variables to runfile header
foreach my $key ( keys %config ) {
	$runfile .= '@'.$key.":".$config{$key}."\n";
}

while(<CONFIG>){
	chomp;
	s/\n//;
	s/\r//;
	
	# Add to runfile string
	$runfile .= "$_\n";
	
	# Ignore comment blocks
	if($_ =~ /^\/\*/){
		$comment_block = 1;
		next;
	}
	if($_ =~ /^\*\//){
		$comment_block = 0;
		next;
	}
	
	# Read the pipeline tree
	if($_ =~ /^(\t*)#/){
		s/^(\t*)#//;
		splice @indents, length($1)+1;
		push @indents, $indents[$#indents]->{$_} = {};
	}
	
}

close(CONFIG);

# If we have a file list input file, take input from there
my @download_fns;
if($file_list){
	unless(-e $file_list){
		print "Error - file list not found: $file_list\nExiting...\n\n";
		exit;
	}
	@files = ();
	open (FILES, $file_list) or die "Can't read $file_list: $!";
	while (<FILES>) {
		chomp;
		if ($_ =~ /^$/) { next; } # Skip blank lines
		my @sections = split(/\t/);
		push @files, $sections[0];
		if(defined($sections[1])){
			push @download_fns, $sections[1];
		} else {
			push @download_fns, 0;
		}
	}
	close(FILES);
}

# Go through the supplied starting files
my @qsubs;
my @job_ids;
my %run_job_ids;
my $job_id;
my $prev_dl_id;
my @outfns;
foreach my $i (0..$#files){
	my $fn = $files[$i];
	my $outfn = $fn."_$pipeline.out";
	
	# Make the run file
	my $runfn = $fn."_$pipeline.run";
	my $date = strftime "%H:%M %d-%m-%Y", localtime;
	my $this_runfile = "/*\n$runfn\nCreated $date\n*/\n\n".$runfile."\n\n";
	
	# Is this filename a URL?
	if ($fn =~ /^(((ht|f)tp(s?))\:\/\/)/){
		
		# Find download filename if it exists
		my $dl_fn;
		if($download_fns[$i]){
			$dl_fn = $download_fns[$i];
		} else {
			my @parts = split("/", $fn);
			$dl_fn = pop(@parts);
		}
		$runfn = $dl_fn."_$pipeline.run";
		$this_runfile = "/*\n$runfn\nFile $dl_fn downloaded from $fn\nCreated $date\n*/\n\n".$runfile."\n\n";
		$outfn = $dl_fn."_$pipeline.out";
		push @outfns, $outfn;
		
		# URL - set up download module qsub job, dependent on previous download job
		$job_id = 'download_'.int(rand(9999));
		my $qsub = "echo \"$Bin/modules/download $runfn $job_id $fn $dl_fn\" | qsub -cwd -V -pe orte 1 -l vf=1G -o $outfn -j y -N $job_id";
		if($prev_dl_id && length($prev_dl_id) > 0 && $prev_dl_id ne 'start_0000'){
			$qsub .= " -hold_jid $prev_dl_id";
		}
		push @qsubs, $qsub;
		push @job_ids, $job_id;
		$prev_dl_id = $job_id;
		
		# Done with the download URL. Call $fn for later stuff
		$fn = $dl_fn;
	
	} elsif(-e $fn) { # Not a URL. Does this file exist?
		# Add the starting filename to the run file
		$job_id = 'start_0000';
		$this_runfile .= "$job_id\t$fn\n";
	
	} else { # Not a URL, file doesn't exist
		print "File $fn doesn't exist.. Skipping..\n";
		next;
	}
	
	# Write status update (now that we have a solid filename)
	warn "Processing file ".($i+1)." - $fn\n";
	
	# Write out the run file
	open (RUNOUT,'>',$runfn) or die "Can't write to $runfn: $!";
	print RUNOUT $this_runfile;
	close(RUNOUT);
	
	# Make up qsub jobs
	make_qsubs (\%module_tree, $job_id, $runfn, $outfn);
	
	# Qsub job to e-mail on completion of this run
	my $run_email_qsub = "echo \"mail -s 'Run ${pipeline}_$fn.run Complete' ".$config{email}." < $outfn || echo 'DID NOT WORK!'\" | qsub -cwd -V -o $outfn -j y -N email_run_complete_$fn -hold_jid ".join(",", @{$run_job_ids{$runfn}});
	push @qsubs, $run_email_qsub;
	
	# Final qsub job to e-mail on completion of ALL JOBS
	if($i == $#files){
		my $final_email_qsub = "echo \"tail -n +1 ".join(" ", @outfns)." | mail -s 'Pipeline ${pipeline} Complete' ".$config{email}."\" | qsub -cwd -V -o $outfn -j y -N email_pipeline_complete -hold_jid ".join(",", @job_ids);
		push @qsubs, $final_email_qsub;
	}
}

sub make_qsubs {
	# Set up parameters for this branch
	my ($mod_tree, $prev_job, $runfn, $outfn) = @_;
	
	# Run through leaves
	foreach ( keys %{$mod_tree} ){
	
		# Set up parameters for these leaves
		my ($module, $parameters) = split(/\s+/, $_, 2);
		my $job_id = $module.'_'.int(rand(9999));
		
		unless($parameters) {
			$parameters = '';
		}
		
		# Find the module file
		my @module_folders = ('./', "$homedir/cf/modules/", "$Bin/modules/");
		my $module_fn;
		foreach (@module_folders){
			if(-e $_."$module"){
				$module_fn = $_."$module";
				last;
			}
		}
		if(!$module_fn){
			die "Can't find pipeline config file $pipeline.config";
		}
		
		# Get options for module
		my $cores = `$module_fn --cores 4`;
		my $mem = `$module_fn --mem`;
		
		if(!$mem || length($mem) == 0){
			$mem = $config{default_mem};
		}
		
		# Create qsub command
		my $qsub = "echo \"$module_fn $runfn $job_id $prev_job $parameters\" | qsub -cwd -V -pe orte $cores -l vf=$mem -o $outfn -j y -N $job_id";
		if(length($prev_job) > 0 && $prev_job ne 'start_0000'){
			$qsub .= " -hold_jid $prev_job";
		}
		push @qsubs, $qsub;
		push @job_ids, $job_id;
		unless(defined $run_job_ids{$runfn}){
			$run_job_ids{$runfn} = ();
		}
		push @{$run_job_ids{$runfn}}, $job_id;
		
		# Recursively call this function if we're not at the end of a branch
		if ( ref $mod_tree->{$_} eq 'HASH') {
			make_qsubs ( $mod_tree->{$_}, $job_id, $runfn, $outfn ) ;
		}
	}
}



# Print qsub jobs to the terminal
foreach(@qsubs){
	if($cl_dryrun){
		print "$_\n\n";
	} else {
		system $_;
	}
}