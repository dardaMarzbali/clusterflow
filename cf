#!/usr/bin/perl
use warnings;
use strict;
use Getopt::Long;
use POSIX qw(strftime);
use FindBin qw($Bin);
use lib "$FindBin::Bin/source";
# use lib "$Bin/../source";
use CF::Constants;
use CF::Helpers;
use CF::Headnodehelpers;

no warnings qw(once);

my $CF_VERSION = $CF::Constants::CF_VERSION;
my $homedir = $ENV{"HOME"}; #$CF::Constants::homedir;
my %config = %CF::Constants::config;
my @pipeline_folders = ('./', "$homedir/clusterflow/pipelines/", "$Bin/pipelines/");
my @module_folders = ("$homedir/clusterflow/modules/", "$Bin/modules/");
my $pipeline;

# Get command line parameters
my $GENOME;
my $cl_genome_path;
my $cl_bowtie_path;
my $cl_gtf_path;
my $SPLIT_FILES = 1;
my $cl_paired_end;
my $cl_single_end;
my $file_list;
my $cl_module;
my $cl_module_params;
my $cl_email;
my $cl_priority;
my $cl_total_cores;
my $cl_total_mem;
my $cl_notifications;
my $cl_list_pipelines;
my $cl_list_modules;
my $cl_list_genomes;
my $cl_dryrun;
my $cl_qstat;
my $cl_qstatall;
my $cl_qstatcolours;
my $cl_make_config;
my $cl_version;
my $cl_help;

my $config_result = GetOptions(
	"genome=s" => \$GENOME,
	"genome_path=s" => \$cl_genome_path,
	"bowtie_path=s" => \$cl_bowtie_path,
	"gtf_path=s" => \$cl_gtf_path,
	"split_files=i" => \$SPLIT_FILES,
	"paired" => \$cl_paired_end,
	"single" => \$cl_single_end,
	"file_list=s" => \$file_list,
	"module=s" => \$cl_module,
	"mod_params=s" => \$cl_module_params,
	"email=s" => \$cl_email,
	"priority=s" => \$cl_priority,
	"cores=i" => \$cl_total_cores,
	"mem=s" => \$cl_total_mem,
	"notifications=s"  => \$cl_notifications,
	"list_pipelines" => \$cl_list_pipelines,
	"list_modules" => \$cl_list_modules,
	"list_genomes" => \$cl_list_genomes,
	"dryrun" => \$cl_dryrun,
	"qstat" => \$cl_qstat,
	"qstatall" => \$cl_qstatall,
	"qstatcols" => \$cl_qstatcolours,
	"make_config" => \$cl_make_config,
	"version" => \$cl_version,
	"help" => \$cl_help
);

die "Could not parse options" unless ($config_result);

# Get the file list
if($cl_module){
	$pipeline = $cl_module;
} else {
	$pipeline = shift(@ARGV);
}
my @files = @ARGV;

# Set up parameters
my $EMAIL = $CF::Constants::EMAIL;
my @NOTIFICATIONS = @CF::Constants::NOTIFICATIONS;
my %GENOME_PATHS = %CF::Constants::GENOME_PATHS;
my %BOWTIE_PATHS = %CF::Constants::BOWTIE_PATHS;
my %GTF_PATHS = %CF::Constants::GTF_PATHS;
my $PRIORITY = $CF::Constants::PRIORITY;
my $TOTAL_CORES = $CF::Constants::TOTAL_CORES;
my $TOTAL_MEM = $CF::Constants::TOTAL_MEM;

if($cl_email){
	$EMAIL = $cl_email;
}
if($cl_notifications){
	my @new_nots = split(//, $cl_notifications);
	@NOTIFICATIONS = ();
	foreach my $not (@new_nots){
		push (@NOTIFICATIONS, 'complete') if($not eq 'c');
		push (@NOTIFICATIONS, 'run') if($not eq 'r');
		push (@NOTIFICATIONS, 'success') if($not eq 's');
		push (@NOTIFICATIONS, 'error') if($not eq 'e');
		push (@NOTIFICATIONS, 'abort') if($not eq 'a');
	}
}
if($cl_genome_path){
	$GENOME_PATHS{$cl_genome_path} = {$cl_genome_path};
	$GENOME = $cl_genome_path;
}
if($cl_bowtie_path){
	$BOWTIE_PATHS{$cl_bowtie_path} = {$cl_bowtie_path};
	$GENOME = $cl_genome_path;
}
if($cl_gtf_path){
	$GTF_PATHS{$cl_gtf_path} = {$cl_gtf_path};
	$GENOME = $cl_genome_path;
}
if($cl_priority){
	$PRIORITY = $cl_priority;
}
if($cl_total_cores){
	$TOTAL_CORES = $cl_total_cores;
}
if($cl_total_mem){
	$TOTAL_MEM = $cl_total_mem;
}
if($cl_module_params && !$cl_module){
	warn "Warning: --mod_params specified without using --module. Ignoring this parameter and continuing..\n";
}

# Printing command line options
if($cl_list_pipelines){
	print "".("=" x 32)."\nCluster Flow - available pipelines\n".("=" x 32)."\n";
	print "Installed pipelines:\n";
	foreach my $folder (@pipeline_folders){
		if(-e $folder){
			print "    Directory $folder\n";
			opendir (DIR, $folder) or die $!;
			my @dir_files = sort readdir(DIR);
			while ( my $file = shift @dir_files ) {
				if(substr($file, -7) eq ".config" && substr($file, 0, -7) ne "clusterflow"){
					print "\t- ".substr($file, 0, -7)."\n";
				}
			}
			closedir(DIR);
		} else {
			print "    Directory $folder (not found)\n";
		}
	}
	print "\n";
	exit;
}
if($cl_list_modules){
	print "".("=" x 32)."\nCluster Flow - available modules\n".("=" x 32)."\n";
	print "Available modules:\n";
	foreach my $folder (@module_folders){
		if(-e $folder){
			print "    Directory $folder\n";
			opendir (DIR, $folder) or die $!;
			my @dir_files = sort readdir(DIR);
			while ( my $file = shift @dir_files ) {
				if($file ne "." && $file ne ".." && $file ne ".svn"){
					print "\t- $file\n";
				}
			}
			closedir(DIR);
		} else {
			print "    Directory $folder (not found)\n";
		}
	}
	print "\n";
	exit;
}
if($cl_list_genomes){
	print "".("=" x 32)."\nCluster Flow - available genomes\n".("=" x 32)."\n";
	print "\nGenome Paths:\n";
	foreach my $key (sort keys %GENOME_PATHS ) {
		my $spaces = " " x (20 - length($key));
		print "\t$key:$spaces$GENOME_PATHS{$key}\n";
	}
	print "\nBowtie Index Base Paths:\n";
	foreach my $key (sort keys %BOWTIE_PATHS ) {
		my $spaces = " " x (20 - length($key));
		print "\t$key:$spaces$BOWTIE_PATHS{$key}\n";
	}
	print "\nGTF File Paths:\n";
	foreach my $key (sort keys %GTF_PATHS ) {
		my $spaces = " " x (20 - length($key));
		print "\t$key:$spaces$GTF_PATHS{$key}\n";
	}
	print "\n";
	exit;
}
if($cl_dryrun){
	print "\n### Cluster Flow is running in Dry Run mode. No cluster jobs will be set off, only printed. Run files will be created. ###\n\n";
	sleep(1);
}
if($cl_qstat){
	if($cl_qstatcolours){
		print CF::Headnodehelpers::parse_qstat(0, 1);
	} else {
		print CF::Headnodehelpers::parse_qstat(0, 0);
	}
	exit;
}
if($cl_qstatall){
	if($cl_qstatcolours){
		print CF::Headnodehelpers::parse_qstat(1, 1);
	} else {
		print CF::Headnodehelpers::parse_qstat(1, 0);
	}
	exit;
}
if($cl_make_config){
	CF::Constants::clusterflow_make_config();
	exit;
} else {
	# Warn user if we don't have a home directory config file
	# (probably means no notifications)
	unless(-e "$homedir/clusterflow/clusterflow.config"){
		warn "\nYou don't seem to have a config file set up in your
home directory! It's a good idea to set one up, so that
you can get e-mailed notifications from Cluster Flow.
To create one, run cf --make_config\n\n\n";
	}
}

if($cl_version){
	print "Cluster Flow v$CF_VERSION\n\n";
	exit;
}
if($cl_help){
	if($pipeline){
		print CF::Constants::clusterflow_pipeline_help($pipeline);
	} else {
		print CF::Constants::clusterflow_help();
	}
	exit;
}
if($cl_module){
	warn "\nUsing a single module instead of a pipeline: $cl_module\n\n";
} elsif(!$pipeline){
	die("Error - no pipeline specified. Use --help for instructions.\nSyntax: cf [flags] pipeline_name file_1 file_2..\n\n");
}

if(!$file_list && scalar(@files) == 0){
	die("Error - no input files specified. Use --help for instructions.\nSyntax: cf [flags] pipeline_name file_1 file_2..\n\n");
}


if($cl_module){
	# Make a temporary pipeline with a single module name
	# Check the module exists
	my $module_found = 0;
	foreach my $folder (@module_folders){
		if(-e $folder."$cl_module"){
			$module_found = 1;
			last;
		}
	}
	if(!$module_found){
		die "Can't find pipeline config file $pipeline.config";
	} else {
		# Do we have any parameters passed for this module?
		my $mparams = "";
		if($cl_module_params){
			$mparams = $cl_module_params;
			$mparams =~ s/^\s+|\s+$//g; # trim whitespace
			$mparams = "\t".$mparams;
		}
		# Make a file handle from a string
		my $pipeline_config = "\n#".$cl_module.$mparams."\n\n";
		open(CONFIG, "<", \$pipeline_config) or die "Can't open variable file handle for single module pipeline: $!\n\n";
	}
} else {
	# Load in the pipeline config file
	my $config_found = 0;
	foreach my $folder (@pipeline_folders){
		if(-e $folder."$pipeline.config"){
			open (CONFIG,$folder."$pipeline.config") or die "Can't read ".$folder."$pipeline.config: $!";
			$config_found = 1;
			last;
		}
	}
	if(!$config_found){
		die "Can't find pipeline config file $pipeline.config";
	}
}

my $runfile;
my %module_tree;
my @indents;
push @indents, \%module_tree;
my $comment_block = 0;

# Write config variables to runfile header
$runfile = CF::Constants::runfile_constants();
if(defined($GENOME) && defined($GENOME_PATHS{$GENOME})){
	$runfile .= "\@genome_path\t".$GENOME_PATHS{$GENOME}."\n";
}
if(defined($GENOME) && defined($BOWTIE_PATHS{$GENOME})){
	$runfile .= "\@bowtie_path\t".$BOWTIE_PATHS{$GENOME}."\n";
}
if(defined($GENOME) && defined($GTF_PATHS{$GENOME})){
	$runfile .= "\@gtf_path\t".$GTF_PATHS{$GENOME}."\n";
}

# Forcing paired end or single end
if ($cl_paired_end){
	$runfile .= "\@force_paired_end\n";
	if($SPLIT_FILES == 1){
		$SPLIT_FILES = 2;
	}
} elsif ($cl_single_end){
	$runfile .= "\@force_single_end\n";
} 

# Parse pipeline config file
while (<CONFIG>){
	chomp;
	s/\n//;
	s/\r//;
	
	# Add to runfile string
	$runfile .= "$_\n";
	
	# Ignore comment blocks
	if($_ =~ /^\/\*/){
		$comment_block = 1;
		next;
	}
	if($_ =~ /^\*\//){
		$comment_block = 0;
		next;
	}
	
	# Required variables
	if($_ =~ /^\@require_genome/ && !$comment_block){
		if(!defined $GENOME){
			warn "\n### Error - The pipeline $pipeline requires a genome to be set with --genome or --genome_path. Exiting... ### \n\n";
			exit;
		} elsif(!defined $GENOME_PATHS{$GENOME}){
			warn "\n### Error ###\nNo genome path found for $GENOME.\n\nAvailable genome paths:\n";
			while ( (my $genome, my $path) = each %GENOME_PATHS ) {
			  warn "\tGenome: $genome, Path: $GENOME_PATHS{$genome}\n";
			}
			warn "\n\nExiting...\n\n";
			exit;
		}
	}
	if($_ =~ /^\@require_bowtie/ && !$comment_block){
		if(!defined $GENOME){
			warn "\n### Error - The pipeline $pipeline requires a genome to be set with --genome or --bowtie_path. Exiting... ### \n\n";
			exit;
		} elsif(!defined $BOWTIE_PATHS{$GENOME}){
			warn "\n### Error ###\nNo genome path found for $GENOME.\n\nAvailable genome paths:\n";
			while ( (my $genome, my $path) = each %BOWTIE_PATHS ) {
			  warn "\tGenome: $genome, Path: $BOWTIE_PATHS{$genome}\n";
			}
			warn "\n\nExiting...\n\n";
			exit;
		}
	}
	if($_ =~ /^\@require_gtf/ && !$comment_block){
		if(!defined $GENOME){
			warn "\n### Error - The pipeline $pipeline requires a genome to be set with --genome or --gtf_path. Exiting... ### \n\n";
			exit;
		} elsif(!defined $GTF_PATHS{$GENOME}){
			warn "\n### Error ###\nNo genome path found for $GENOME.\n\nAvailable genome paths:\n";
			while ( (my $genome, my $path) = each %GTF_PATHS ) {
			  warn "\tGenome: $genome, Path: $GTF_PATHS{$genome}\n";
			}
			warn "\n\nExiting...\n\n";
			exit;
		}
	}
	
	# Read the pipeline tree
	if($_ =~ /^(\t*)#/ && !$comment_block){
		s/^(\t*)#//;
		splice @indents, length($1)+1;
		push @indents, $indents[$#indents]->{$_} = {};
	}
	
}

close(CONFIG);

# If we have a file list input file, take input from there
my @download_fns;
if($file_list){
	unless(-e $file_list){
		print "Error - file list not found: $file_list\nExiting...\n\n";
		exit;
	}
	@files = ();
	open (FILES, $file_list) or die "Can't read $file_list: $!";
	while (<FILES>) {
		chomp;
		if ($_ =~ /^$/) { next; } # Skip blank lines
		my @sections = split(/\t/);
		push @files, $sections[0];
		if(defined($sections[1])){
			push @download_fns, $sections[1];
		} else {
			push @download_fns, 0;
		}
	}
	close(FILES);
}

# Work out quota of cores and memory allowed per job
# Work out memory allocation in bytes
$TOTAL_MEM = CF::Helpers::human_readable_to_bytes($TOTAL_MEM);
# Count terminal leaves in pipeline and number of files
my $num_leaves = count_leaves(\%module_tree, 0);
my $num_files = scalar @files;
# Calculate per-job resources
my $cores_allocation = int( $TOTAL_CORES / ($num_leaves * $num_files));
my $memory_allocation = int( $TOTAL_MEM / ($num_leaves * $num_files));
# Sanity checks
if($cores_allocation < 1){
	$cores_allocation = 1; # minimum one core
}
if($memory_allocation < 104857600){
	$memory_allocation = 104857600; # minimum one 100 Mb
}

sub count_leaves {
	# Set up parameters
	my ($mod_tree, $num_leaves) = @_;
	
	# Run through leaves on this branch
	foreach ( keys %{$mod_tree} ){
		
		my $num_keys = scalar keys(%{$mod_tree->{$_}});
		
		# Recursively call this function if we're not at the end of a branch
		if ($num_keys > 0) {
			$num_leaves = count_leaves ( $mod_tree->{$_}, $num_leaves ) ;
		
		# No children, add one to the count for this leaf
		} else {
			$num_leaves++;
		}
	}
	
	return $num_leaves;
}

# Go through the supplied starting files
my @qsubs;
my @job_ids;
my $jid_base = 'cf_'.$pipeline.'_'.time.'_';
my %run_job_ids;
my $job_id;
my $prev_dl_id;
my @outfns;
my @finished_run_ids;
for (my $i = 0; $i <= $#files; $i++){
	my $fn = $files[$i];
	my $first_fn = $fn;
	my $outfn = $fn."_$pipeline.out";
	
	# Make the run file
	my $runfn = $fn."_$pipeline.run";
	my $date = strftime "%H:%M, %d-%m-%Y", localtime;
	my $this_runfile = "/*\n$runfn\nCreated at $date\n*/\n\n".$runfile."\n\n";
	
	# Add files to run file
	my $max_i = $i + $SPLIT_FILES;
	my $counter = 0;
	for (; $i < $max_i; $i++){
		$counter++;
		if($i > $#files) {
			last;
		}
		
		$fn = $files[$i];
		
		# Is this filename a URL?
		if ($fn =~ /^(((ht|f)tp(s?))\:\/\/)/){
			
			# Find download filename if it exists
			my $dl_fn;
			if($download_fns[$i]){
				$dl_fn = $download_fns[$i];
			} else {
				my @parts = split("/", $fn);
				$dl_fn = pop(@parts);
			}
			$runfn = $dl_fn."_$pipeline.run";
			$outfn = $dl_fn."_$pipeline.out";
			push @outfns, $outfn;
			
			# URL - set up download module qsub job, dependent on previous download job
			$job_id = $jid_base.'download_'.int(rand(999));
			my $qsub = "echo \"$Bin/modules/cf_download $runfn $job_id $fn $dl_fn\" | qsub -cwd -V -pe orte 1 -l vf=1G -o $outfn -j y -N $job_id";
			if($prev_dl_id && length($prev_dl_id) > 0 && $prev_dl_id ne 'start_000'){
				$qsub .= " -hold_jid $prev_dl_id";
			}
			push @qsubs, $qsub;
			push @job_ids, $job_id;
			$prev_dl_id = $job_id;
			
			# Done with the download URL. Set $fn for later stuff
			$fn = $dl_fn;
			if($counter == 1){
				$first_fn = $dl_fn;
			}
		
		} elsif(-e $fn) { # Not a URL. Does this file exist?
			# Add the starting filename to the run file
			$job_id = 'start_000';
			$this_runfile .= "$job_id\t$fn\n";
			push @outfns, $outfn;
		
		} else { # Not a URL, file doesn't exist
			print "\nFile $fn doesn't exist.. Skipping..\n\n";
			next;
		}
		
		# Write status update (now that we have a solid filename)
		warn "Processing file ".($i+1)." - $fn\n";
	
	}
	$i--; # Loop increments $i when it finishes. Revert this increment before next loop
	$fn = $first_fn;
	
	# Deduplicate output fn array
	@outfns = do { my %h; @h{@outfns} = @outfns; values %h };
	
	# Write out the run file
	open (RUNOUT,'>',$runfn) or die "Can't write to $runfn: $!";
	print RUNOUT $this_runfile;
	close(RUNOUT);
	
	# Make up qsub jobs
	make_qsubs (\%module_tree, $job_id, $runfn, $outfn);
	
	# Qsub job to execute on completion of this run
	my $run_finish_id = $jid_base."email_run_complete_".int(rand(999));
	my $run_finish_qsub = "echo \"$Bin/modules/cf_run_finished $runfn $run_finish_id null 1 1G $pipeline $outfn\" | qsub -cwd -V -o $outfn -j y -N $run_finish_id -hold_jid ".join(",", @{$run_job_ids{$runfn}});
	push @qsubs, $run_finish_qsub;
	push @finished_run_ids, $run_finish_id;
	
	# Final qsub job to execute on completion of ALL JOBS
	if($i == $#files){
		my $all_runs_finish_qsub = "echo \"$Bin/modules/cf_runs_all_finished $runfn $run_finish_id null 1 1G $pipeline ".join(" ", @outfns)."\" | qsub -cwd -V -o $outfn -j y -N ".$jid_base."email_pipeline_complete_${pipeline} -hold_jid ".join(",", @finished_run_ids);
		push @qsubs, $all_runs_finish_qsub;
	}
}

sub make_qsubs {
	# Set up parameters for this branch
	my ($mod_tree, $prev_job, $runfn, $outfn) = @_;
	
	# Work out qsub notification settings
	my $notifications = "";
	if(defined($EMAIL) && length($EMAIL) > 0 && @NOTIFICATIONS){
		my $count = 0;
		$notifications = "-M $EMAIL -m ";
		foreach my $not (@NOTIFICATIONS){
			if($not eq 'suspend'){
				$notifications .= 's';
				$count++;
			}
			if($not eq 'end'){
				$notifications .= 'e';
				$count++;
			}
			if($not eq 'abort'){
				$notifications .= 'a';
				$count++;
			}
		}
		if($count == 0){
			$notifications = "";
		}
	}
	
	# Run through leaves
	foreach ( keys %{$mod_tree} ){
	
		# Set up parameters for these leaves
		my ($module, $parameters) = split(/\s+/, $_, 2);
		my $job_id = $jid_base.$module.'_'.int(rand(999));
		
		unless(length($module) > 0){
			next;
		}
		unless($parameters) {
			$parameters = '';
		}
		
		# Find the module file
		my @module_folders = ('./', "$homedir/cf/modules/", "$Bin/modules/");
		my $module_fn;
		foreach (@module_folders){
			if(-e $_."$module"){
				$module_fn = $_."$module";
				last;
			}
		}
		if(!$module_fn){
			die "Can't find pipeline config file $pipeline.config";
		}
		
		# Get options for module
		my $cores = `$module_fn --cores $TOTAL_CORES`;
		my $mem = `$module_fn --mem $TOTAL_MEM`;
		my $required_modules = `$module_fn --modules`;
		
		if(!$cores || length($cores) == 0){
			$cores = 1;
		}
		if(!$mem || length($mem) == 0){
			$mem = $config{default_mem};
		}
		if($required_modules && length($required_modules) > 0){
			my @req_modules = split(",", $required_modules);
			foreach my $mod (@req_modules) {
				my $bash_string = `/usr/bin/modulecmd bash load $mod`;
				if($bash_string && length($bash_string) > 0){
					my @bashes = split(';', $bash_string);
					foreach my $bash (@bashes){
						my @envs = split('=', $bash);
						if($envs[0] ne 'export' && defined($envs[1])){
							$envs[1] =~ s/\\//g; # Hacky fix to get rid of weird backslash problem
							$ENV{$envs[0]} = $envs[1];
						}
					}
				}
			}
		}
		
		# Create qsub command
		my $qsub = "echo \"$module_fn $runfn $job_id $prev_job $cores $mem $parameters\" | qsub -cwd -V -pe orte $cores -l vf=$mem -p $PRIORITY -o $outfn -j y $notifications -N $job_id";
		if(length($prev_job) > 0 && $prev_job ne 'start_0000'){
			$qsub .= " -hold_jid $prev_job";
		}
		
		push @qsubs, $qsub;
		push @job_ids, $job_id;
		unless(defined $run_job_ids{$runfn}){
			$run_job_ids{$runfn} = ();
		}
		push @{$run_job_ids{$runfn}}, $job_id;
		
		# Recursively call this function if we're not at the end of a branch
		if ( ref $mod_tree->{$_} eq 'HASH') {
			make_qsubs ( $mod_tree->{$_}, $job_id, $runfn, $outfn ) ;
		}
	}
}



# Print qsub jobs to the terminal
foreach(@qsubs){
	if($cl_dryrun){
		print "$_\n\n";
	} else {
		system $_;
	}
}